<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Supervised Contrastive Learning for Generalizable and Explainable Deepfakes Detection</title>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6">
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <style>
      body {
        font-family:Arial;
        font-size:20px;
        margin:60px auto;
        width:auto;
        max-width:900px;
      }

      hr {
        border:0;
        height:1.0px;
        background-image:linear-gradient(to right, rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3));
      }

      .gap-30 {
      width:100%;
      height:30px;
      }

      .gap-20 {
      width:100%;
      height:20px;
      }

      .gap-10 {
      width:100%;
      height:10px;
      }

      .gap-5 {
      width:100%;
      height:5px;
      }
      .paper {
        max-width: 700px;
      }
      @media (max-width: 910px) {
        .paper {
          max-width: 500px;
        }
      }
      @media (max-width: 610px) {
        .paper {
          max-width: 300px;
        }
      }
    </style>
  </head>

  <div class="container">
  <body>

    <center><span style="font-size:40px">
      Supervised Contrastive Learning for Generalizable and Explainable Deepfakes Detection
    </span></center>
    <div class="gap-20"></div>

    <!---------------------  authors --------------------->
    <center>
    <span style="font-size:20px;">
          &nbsp;
          <div style="display:inline-block">
          <a href="https://xuyingzhongguo.github.io">Ying Xu</a>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a>Kiran Raja</a>,
          </div>
          &nbsp;
          <div style="display:inline-block">
          <a>Marius Pedersen</a>
          </div>
    </span>
    <div class="gap-20"></div>
    
	</center>
    <!--------------------- affiliations --------------------->
    <div class="gap-5"></div>
    <div class="row">
      <div class="col-md-2"></div>
      <div class="col-md-8 text-center"> <!-- Add the "text-center" class to center-align the content -->
        <p>
          <span style="font-size:20px">
            Norwegian University of Science and Technology
          </span>
        </p>
      </div>
      <div class="col-md-2"></div>
    </div>
    <hr>

    <!--------------------- links --------------------->
    <div class="gap-10"></div>

    <center>
    <span style="font-size:20px"> 
      <b>WACVW 2023</b>
      &nbsp; 
      [<a href="https://openaccess.thecvf.com/content/WACV2022W/XAI4B/papers/Xu_Supervised_Contrastive_Learning_for_Generalizable_and_Explainable_DeepFakes_Detection_WACVW_2022_paper.pdf">paper</a>]
      &nbsp;
      [<a href="bibtex.txt">BibTeX</a>]
      &nbsp; 
      [<a href="https://github.com/xuyingzhongguo/deepfake_supcon">code</a>]
	&nbsp; 
	[<a href="https://youtu.be/kqRzM8_z0G0">Video</a>]
    </span>
    <div class="gap-20"></div>

    </center>
  <center><img width="80%" src="images/teaser.png"></center>
  <hr>
  <!--------------------- abstract --------------------->
  <div class="gap-20"></div>
  <center><b><span style="font-size:25px">Abstract</span></b><br></center>
  <div class="gap-10"></div>
    <p align="justify"> 
      We propose a generalizable detection model that can detect novel and unknown/unseen DeepFakes using a supervised contrastive (SupCon) loss. As DeepFakes can resemble the original image/video to a greater extent in terms of appearance and it becomes challenging to secern them, we propose to exploit the contrasts in the representation space to learn a generalizable detector. We further investigate the features learnt from our proposed approach for explainability. The analysis for explainability of the models advocates the need for fusion and motivated by this, we fuse the scores from the proposed SupCon model and the Xception network to exploit the variability from different architectures. The proposed model consistently performs better compared to the single model on both known data and unknown attacks consistently in a seen data setting and an unseen data setting, with generalizability and explainability as a basis. We obtain the highest accuracy of 78.74% using proposed SupCon model and an accuracy of 83.99% with proposed fusion in a true open-set evaluation scenario where the test class is unknown at the training phase.
    </p>
  <hr>
<!--------------------- content --------------------->
  <div class="gap-20"></div>
    <b><span style="font-size:25px">Proposed SupCon Model</span></b><br>
    <p></p>
    <p align="justify">We first present the baseline results of closed-set classification in Table 1, along with the open set classification accuracy to empirically validate the proposed approach of SupCon for DeepFakes detection.</p>
    <center><img width="100%" src="images/table1.png"></center>
    <hr>

  <div class="gap-20"></div>
    <b><span style="font-size:25px">Fusion Model</span></b><br>
    <p></p>
    <p align="justify">As the scores may be ideal for different tasks due to the nature of learning and to maximally use the scores from each network, we propose to employ a weighted fusion of the final score from the last activation layer. The architecture of our proposed fusion for DeepFakes detection is presented in Figure below.</p>
    <center><img width="80%" src="images/fusion_model.png"></center>
    <p align="justify">Table below presents the results obtained from the proposed
      fusion approach in comparison to the proposed SupCon model and Xception model. As it can be noted, our fusion model consistently performs better than a single model,
      while reaching at-least the lower bound of the performance
      of Xception model in three cases (not accompanying â†‘).
      The obtained results with a consistent gain indicate the complementarity of our proposed approach in improving the
      generalizability.</p>
      <center><img width="50%" src="images/fusion_result.png"></center>
    <hr>

  <div class="gap-20"></div>
    <b><span style="font-size:25px">Activation Maps Visualization</span></b><br>
    <p></p>
    <p align="justify">Figure below presents the heatmaps corresponding to the last layer of the proposed SupCon overlaid with different kinds of DeepFakes (DF, F2F, FS, and NT). We note that the SupCon focuses on the silhouette on the face region where the manipulation exists. Our assertion of the SupCon applicable to DeepFakes detection is corroborated through visual analysis. We also do a similar analysis on the Xception network as presented in Figure below. Noting from the visual analysis, it is evident that the Xception network focuses on the regions inside the face region such as foreheads, eyebrows, and eyes. The focus of heatmaps on different areas of the face region clearly suggests the complementarity of the networks.</p>
    <center><img width="60%" src="images/visual.png"></center>
    <center><p style="font-size:18px"><i>Heatmap for visualization of feature importance comparison from proposed Xception(top) and SupCon(bottom) mode.</i></p></center>
    <hr>
</body>
</div>

<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="js/bootstrap.min.js"></script>

</html>
